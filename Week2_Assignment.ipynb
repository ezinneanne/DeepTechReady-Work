{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1MkBoyl533WZGKuP0qtzS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ezinneanne/DeepTechReady-Work/blob/new_branch/Week2_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment: Build and Evaluate Multiclass CNN Models for Fish or Boat Dataset"
      ],
      "metadata": {
        "id": "yFFD11yolG9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Boat Dataset"
      ],
      "metadata": {
        "id": "R3-An1nvlSpf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2jDjuLfjuSF"
      },
      "outputs": [],
      "source": [
        "# Mounting Gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries for data handling and model building\n",
        "import numpy as np  # Importing numpy for numerical operations\n",
        "import tensorflow as tf  # Importing TensorFlow for deep learning functionality\n",
        "from tensorflow import keras  # Importing Keras API for building and training models\n",
        "from tensorflow.keras import layers  # Importing Keras layers to build neural networks\n",
        "from tensorflow.keras.models import Sequential  # Importing Sequential model for linear stacking of layers"
      ],
      "metadata": {
        "id": "LXeRzaT5miWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining parameters for image processing\n",
        "batch_size = 32  # Set batch size for loading data (number of samples per batch)\n",
        "img_height = 180  # Set height for resizing input images\n",
        "img_width = 180  # Set width for resizing input images"
      ],
      "metadata": {
        "id": "m0Ipcew0mlPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to your dataset (the path will be different frp, what u have)\n",
        "data_dir = \"/content/drive/MyDrive/3MTT/Lung dataset (Class).zip\"\n",
        "\n",
        "!mkdir /content/data # Make a new directory in Colab to store the extracted dataset\n",
        "\n",
        "!unzip -q '{data_dir}' -d /content/data # Unzip the zipped file. the '-q' hides the extraction logs, u can remove it to see what happens while extracting"
      ],
      "metadata": {
        "id": "rOW8GvVcm8Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/data/lung dataset'"
      ],
      "metadata": {
        "id": "IhH4pIF4nILZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and split data into training and validation sets using image_dataset_from_directory\n",
        "\n",
        "# Training set\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "\n",
        "  data_dir,  # Path to the dataset\n",
        "  validation_split=0.2,  # Split 20% of the data for validation\n",
        "  subset=\"training\",  # Specify this call to get the training subset\n",
        "  seed=123,  # Set a seed for reproducibility (same data split every time)\n",
        "  image_size=(img_height, img_width),  # Resize images to match the required input shape\n",
        "  batch_size=batch_size  # Set batch size for loading images\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "# Validation set (this uses the same validation_split=0.2 to ensure consistency)\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "\n",
        "  data_dir,  # Path to the dataset\n",
        "  validation_split=0.2,  # Same validation split to get the remaining 20% for validation\n",
        "  subset=\"validation\",  # Specify this call to get the validation subset\n",
        "  seed=123,  # Use the same seed to ensure the same split as for training data\n",
        "  image_size=(img_height, img_width),  # Resize images to the same size as training data\n",
        "  batch_size=batch_size  # Same batch size for validation data\n",
        ")"
      ],
      "metadata": {
        "id": "yW74kkFjnQOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training class names:\", train_ds.class_names)\n",
        "print(\"Validation class names:\", val_ds.class_names)"
      ],
      "metadata": {
        "id": "TTkRX-K2nhDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a sequential CNN model\n",
        "model = Sequential([\n",
        "\n",
        "    # First convolutional block\n",
        "    layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(img_height, img_width, 3)),\n",
        "    # 32 filters, 3x3 kernel, ReLU activation, input shape for RGB image\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    # Second conv layer with 64 filters, keeps dimensions the same due to 'same' padding\n",
        "\n",
        "    layers.MaxPooling2D(),\n",
        "    # Downsamples feature maps using 2x2 pool size (default)\n",
        "\n",
        "    layers.Dropout(0.25),\n",
        "    # Randomly drops 25% of the nodes to reduce overfitting\n",
        "\n",
        "    # Second convolutional block\n",
        "    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    # Another conv layer with 64 filters\n",
        "\n",
        "    layers.MaxPooling2D(),\n",
        "    # Downsampling again\n",
        "\n",
        "    layers.Dropout(0.25),\n",
        "    # Dropout to regularize\n",
        "\n",
        "    # Third convolutional block\n",
        "    layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    # Deeper conv layer with 128 filters\n",
        "\n",
        "    layers.MaxPooling2D(),\n",
        "    # Downsample\n",
        "\n",
        "    layers.Dropout(0.25),\n",
        "    # More dropout for regularization\n",
        "\n",
        "    # Fully connected (dense) layers\n",
        "    layers.Flatten(),\n",
        "    # Flatten 3D feature maps into 1D vector for dense layers\n",
        "\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    # Dense layer with 128 neurons\n",
        "\n",
        "    layers.Dropout(0.5),\n",
        "    # Dropout of 50% to further prevent overfitting\n",
        "\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "    # Output layer with 1 neuron (for binary classification), sigmoid activation for probability output\n",
        "])\n",
        "\n",
        "# Compile the model with optimizer, loss, and evaluation metric\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),  # Adaptive optimizer\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),  # Binary loss, using logits\n",
        "    metrics=['accuracy']  # Track accuracy during training/validation\n",
        ")"
      ],
      "metadata": {
        "id": "3gVtW3xHnsIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "WZJRmiAvoyUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 13828 // batch_size\n",
        "epochs"
      ],
      "metadata": {
        "id": "FrBi91q1o7PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=2\n",
        "\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "P0o-awxIpGNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules from TensorFlow's Keras API\n",
        "\n",
        "# Import the 'layers' and 'models' submodules from tensorflow.keras\n",
        "# 'layers' is used to build different types of neural network layers (e.g., Conv2D, Dense, etc.)\n",
        "# 'models' provides APIs to create and manage models (Sequential and Functional APIs)\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Import the pre-trained MobileNetV2 model from keras.applications\n",
        "# MobileNetV2 is a lightweight deep convolutional neural network architecture for mobile and edge devices\n",
        "# It can be used as a feature extractor or a full model for transfer learning\n",
        "from tensorflow.keras.applications import MobileNetV2"
      ],
      "metadata": {
        "id": "yttn06e1pQiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining parameters for image processing\n",
        "batch_size = 32  # Set batch size for loading data (number of samples per batch)\n",
        "img_height = 224  # Set height for resizing input images\n",
        "img_width = 224  # Set width for resizing input images"
      ],
      "metadata": {
        "id": "JiNRT4qypeIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MobileNetV2 model with pre-trained weights from ImageNet\n",
        "# weights='imagenet' means the model is loaded with weights learned from training on the ImageNet dataset\n",
        "# input_shape specifies the shape of input images (height, width, 3 channels for RGB)\n",
        "# include_top=False excludes the fully connected layers at the top of the model (used for classification in ImageNet)\n",
        "# This allows you to add your own custom classification layers on top (for transfer learning)\n",
        "base_model = MobileNetV2(weights='imagenet', input_shape=(img_height, img_width, 3))\n",
        "\n",
        "# Freeze the base model so its weights wonâ€™t be updated during training\n",
        "# This helps retain the valuable features learned from ImageNet and trains only the new custom layers on top\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "VluSCRVqprM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = models.Sequential([\n",
        "#     base_model,\n",
        "#     layers.AveragePooling2D(),\n",
        "#     layers.Dense(128, activation='relu'),\n",
        "#     layers.Dropout(0.5),\n",
        "#     layers.Dense(1, activation='sigmoid')\n",
        "# ])\n",
        "\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "epochs = 2\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "-7momd0MqAC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load the image and preprocess it\n",
        "def preprocess_image(img_path, img_height, img_width):\n",
        "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    print(img_array.shape)\n",
        "    return img_array"
      ],
      "metadata": {
        "id": "pL_ZyL9gqMZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your image\n",
        "img_path = '/content/Normal-6892.png'\n",
        "\n",
        "# Preprocess the image\n",
        "img_array = preprocess_image(img_path, img_height, img_width)\n",
        "\n",
        "# Predict\n",
        "prediction = model.predict(img_array)\n",
        "prediction"
      ],
      "metadata": {
        "id": "cRI1NP8zqaWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction to class label\n",
        "if prediction[0][0] > 0.5:\n",
        "    print(\"Predicted class: 1 (Positive)\")\n",
        "else:\n",
        "    print(\"Predicted class: 0 (Negative)\")"
      ],
      "metadata": {
        "id": "qkOJzXwMqnnH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}